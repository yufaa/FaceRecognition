{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a021baa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:19:18.232509Z",
     "start_time": "2023-08-04T04:19:18.221253Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "def haar(img):\n",
    "    face_roi = []\n",
    "    status = False\n",
    "    # Load Haar Cascade classifier for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    # Convert the image to grayscale (required for face detection)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the image using the face_cascade\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "    # Draw bounding boxes around the detected faces and display the image\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw a rectangle around the detected face\n",
    "        face_roi = img[y:y+h, x:x+w]\n",
    "        status = True\n",
    "    return status,face_roi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7df1c79",
   "metadata": {},
   "source": [
    "# SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71680c06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:19:26.067625Z",
     "start_time": "2023-08-04T04:19:25.195449Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading the image\n",
    "img = cv2.imread('../dataset/Yudha/IMG_4828.jpg')\n",
    "status,haarnya=haar(img)\n",
    "# Applying SIFT detector\n",
    "sift = cv2.SIFT_create(500)\n",
    "kpts, des = sift.detectAndCompute(haarnya, None)\n",
    "# Marking the keypoint on the image using circles\n",
    "img=cv2.drawKeypoints(haarnya, kpts , haarnya ,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "print(f\" jumlah keypoint terbentuk {len(kpts)}\")\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd91e2",
   "metadata": {},
   "source": [
    "# bovw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dc8a8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:19:32.893750Z",
     "start_time": "2023-08-04T04:19:32.847187Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#kmeans works only on float, so convert integers to float\n",
    "descriptors_float = des.astype(float)  \n",
    "\n",
    "# Perform k-means clustering and vector quantization\n",
    "\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "k = 200  #dari total 500 diambil hanya 200\n",
    "voc, variance = kmeans(obs=descriptors_float, k_or_guess=k, iter=5) \n",
    "\n",
    "\n",
    "# Calculate the histogram of features and represent them as vector\n",
    "#vq Assigns codes from a code book to observations.\n",
    "im_features = np.zeros((1, k), \"float32\")\n",
    "for i in range(1):\n",
    "    words, distance = vq(des,voc)\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "print(im_features.shape)\n",
    "print(im_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b4283",
   "metadata": {},
   "source": [
    "# Feature Extraction  (HAAR+ SIFT+ BOVW)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ca128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:22:32.462878Z",
     "start_time": "2023-08-04T04:19:36.376576Z"
    }
   },
   "outputs": [],
   "source": [
    "#menentukan direktori/folder data citra yang akan dibuka\n",
    "dirname = '../dataset/'  \n",
    "\n",
    "#menentukan ukuran tinggi dan lebar gambar\n",
    "height = 225\n",
    "width = 225\n",
    "dim = (width, height)\n",
    "#BRISK is a good replacement to SIFT. ORB also works but didn;t work well for this example\n",
    "# brisk = cv2.BRISK_create(30)\n",
    "sift = cv2.SIFT_create()\n",
    "#mengumpulkan data citra yang akan dibuka dalam satu array\n",
    "tampungan_data = [] \n",
    "tampungan_label = []\n",
    "for path, subdirs, files in os.walk(dirname):\n",
    "    print(path)\n",
    "    for name in files:\n",
    "        img_path = (os.path.join(path, name))  #baca path data\n",
    "        if (img_path.endswith(\"jpg\")): #dengan file berekstensi jpg\n",
    "            img = cv2.imread(img_path) #baca gambar\n",
    "            status, haarnya = haar(img)\n",
    "            # print(f\"Ini statusnya {status}\")\n",
    "            if(status):\n",
    "                resized=cv2.resize(haarnya,dim, interpolation=cv2.INTER_LINEAR) #resize\n",
    "                kpts, des = sift.detectAndCompute(resized, None)\n",
    "                tampungan_data.append(des)\n",
    "                \n",
    "                path_parts = path.split('/')\n",
    "                # Mengambil elemen terakhir dari path_parts sebagai kata terakhir\n",
    "                last_word = path_parts[-1]\n",
    "                #preprocessing data / segentasi  boleh dilakukan disini\n",
    "                tampungan_label.append(last_word)\n",
    "    X = np.array(tampungan_data, dtype=object) \n",
    "    y = np.array(tampungan_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72825f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:24:14.350656Z",
     "start_time": "2023-08-04T04:24:07.713667Z"
    }
   },
   "outputs": [],
   "source": [
    "descriptors = None\n",
    "for descriptor in X:\n",
    "    if descriptors is None:\n",
    "        descriptors = descriptor\n",
    "    else:\n",
    "        descriptors = np.vstack((descriptors, descriptor)) #gunakan untuk menggabungkan deskriptor menjadi satu tumpukan\n",
    "\n",
    "#kmeans works only on float, so convert integers to float\n",
    "descriptors_float = descriptors.astype(float)  \n",
    "# Perform k-means clustering and vector quantization\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "\n",
    "k = 200  #k means with 100 clusters gives lower accuracy for the aeroplane example\n",
    "voc, variance = kmeans(obs=descriptors_float, k_or_guess=k, iter=5) \n",
    "\n",
    "# Calculate the histogram of features and represent them as vector\n",
    "#vq Assigns codes from a code book to observations.\n",
    "im_features = np.zeros((len(y), k), \"float32\")\n",
    "for i in range(len(y)):\n",
    "    words, distance = vq(X[i],voc)\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "print(im_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c10cc71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:24:19.651965Z",
     "start_time": "2023-08-04T04:24:18.190001Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "list_label=np.unique(y) #mendapatkan label unik\n",
    "label_dict = {label: idx for idx, label in enumerate(list_label)} #masukkan dalam list\n",
    "print(f\"{label_dict} jumlah data: {len(y)}\")\n",
    "\n",
    "label_numerik = [label_dict[s] for s in y] #ubah kedalam numerik\n",
    "label_numerik_array = np.array(label_numerik)\n",
    "\n",
    "# Visualisasikan dalam jumlah dalam plot\n",
    "sns.countplot(x=label_numerik_array)\n",
    "plt.xlabel('Numeric Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count Plot for Numeric Labels')\n",
    "plt.show()  \n",
    "\n",
    "# simpan dalam file npy untuk labeling\n",
    "np.save('../weight/label_knn.npy', label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d5ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:24:21.031124Z",
     "start_time": "2023-08-04T04:24:20.805017Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #library untuk train test split\n",
    "\n",
    "#melakukan splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(im_features, label_numerik_array,test_size=0.20, stratify=label_numerik_array) \n",
    "#train size adalah persentase data test yang di-split dengan proporsi label yang sama\n",
    "\n",
    "print(\"X_train: \"+str(X_train.shape))\n",
    "print(\"X_test: \"+str(X_test.shape))\n",
    "print(\"y_train: \"+str(y_train.shape))\n",
    "print(\"y_test: \"+str(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecf0cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:24:21.962043Z",
     "start_time": "2023-08-04T04:24:21.835474Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "import seaborn as sns\n",
    "model = KNeighborsClassifier(n_neighbors=5, metric=\"minkowski\") #knn dengan nilai n ditentukan\n",
    "model.fit(X_train, y_train) #pastikan model di \"fit\" = proses latih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c9525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:24:23.990108Z",
     "start_time": "2023-08-04T04:24:23.665180Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the metric distances for each label separately with different marker shapes\n",
    "plt.figure(figsize=(8, 6))\n",
    "distances, _ = model.kneighbors(X_train)\n",
    "\n",
    "# Dictionary to map label to marker shape\n",
    "marker_dict = {0: 's', 1: '^', 2: 'o'}\n",
    "\n",
    "for label in np.unique(y_train):\n",
    "    # Get the indices of data points belonging to the current label\n",
    "    label_indices = np.where(y_train == label)[0]\n",
    "    \n",
    "    # Get the distances to the k nearest neighbors for data points of the current label\n",
    "    label_distances = np.mean(distances[label_indices], axis=1)\n",
    "    \n",
    "    # Plot the distances for the current label with the corresponding marker shape\n",
    "    plt.scatter(X_train[label_indices, 0], X_train[label_indices, 1], c=label_distances, cmap='plasma', edgecolors='k', label=f\"Class {label}\", marker=marker_dict[label])\n",
    "\n",
    "plt.colorbar(label='Average Distance to k Nearest Neighbors')\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.title(\"KNN - Metric Distance Visualization for Each Label\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f835a4f6",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb8a230",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:24:25.016789Z",
     "start_time": "2023-08-04T04:24:25.004108Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test) #predict untuk memprediksi data test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5efea",
   "metadata": {},
   "source": [
    "# Evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f21f5f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:24:26.334366Z",
     "start_time": "2023-08-04T04:24:26.159949Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Plot the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50517241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:24:27.132503Z",
     "start_time": "2023-08-04T04:24:27.123044Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred)) #evaluasi hasil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a539b7",
   "metadata": {},
   "source": [
    "# Test Gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f142fd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:25:33.336025Z",
     "start_time": "2023-08-04T04:25:31.337934Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np  \n",
    "\n",
    "url= '../dataset/Yudha/IMG_4941.jpg'\n",
    "img=cv2.imread(url)\n",
    "plt.figure()\n",
    "plt.title(\"Data Test\")\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "#pastikan langkah preprocessing yang dilakukan sama dengan data train\n",
    "status,haarnya=haar(img)\n",
    "img_resize = cv2.resize(haarnya,(225,225))\n",
    "#tampilkan hasil\n",
    "plt.figure()\n",
    "plt.title(\"Hasil Haar\")\n",
    "plt.imshow(cv2.cvtColor(img_resize, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Hasil Sift\")\n",
    "# sift = cv2.SIFT_create()\n",
    "sift = cv2.SIFT_create(nfeatures=500, nOctaveLayers=9, contrastThreshold=0.03, edgeThreshold=10, sigma=1.6)\n",
    "kpts, des = sift.detectAndCompute(img_resize, None)\n",
    "# Marking the keypoint on the image using circles\n",
    "img=cv2.drawKeypoints(img_resize, kpts , img_resize ,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "print(f\" jumlah keypoint terbentuk {len(kpts)}\")\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# bovw\n",
    "#kmeans works only on float, so convert integers to float\n",
    "descriptors_float = des.astype(float)  \n",
    "# Perform k-means clustering and vector quantization\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "k = 200  #dari total 500 diambil hanya 200\n",
    "voc, variance = kmeans(obs=descriptors_float, k_or_guess=k, iter=5) \n",
    "# Calculate the histogram of features and represent them as vector\n",
    "#vq Assigns codes from a code book to observations.\n",
    "im_features = np.zeros((1, k), \"float32\")\n",
    "for i in range(1):\n",
    "    words, distance = vq(des,voc)\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "print(im_features.shape)\n",
    "\n",
    "print(f\"ukuran data test {im_features.shape}\") #sama dengan input shape\n",
    "\n",
    "# Mengecek hasil klasifikasi pada salah satu dataset\n",
    "probability=model.predict_proba(im_features)\n",
    "print(f\"nilai probabilitas {probability}\") #tampilkan nilai probabilitas tiap kelas\n",
    "\n",
    "\n",
    "\n",
    "for ind,val in enumerate(label_dict): #mendapatkan nama kelas dan hasil akurasi\n",
    "    print(f'{val} = {probability[0][ind]*100}%')\n",
    "    \n",
    "    \n",
    "hasil = np.argmax(probability, axis=-1) #mendapatkan kelas dari probabilitas terbaik\n",
    "key_found = [key for key, value in label_dict.items() if value == hasil] #dapatkan namanya\n",
    "print(f\"prediksinya: {key_found}\")\n",
    "print(f\"The predicted image is : {str(hasil)} -> {key_found}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd3b4ff",
   "metadata": {},
   "source": [
    "# Simpan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65516903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:24:35.369921Z",
     "start_time": "2023-08-04T04:24:35.360928Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('../weight/model_haar_sift_knn.pkl', 'wb')) #simpan dalam file.pkl\n",
    "# loaded_model = pickle.load(open('model_haar_knn.pkl', 'rb')) # load model yg dibuat\n",
    "\n",
    "# result = loaded_model.predict(X_test) \n",
    "# print(classification_report(y_test, result)) #evaluasi hasil best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2ff00c",
   "metadata": {},
   "source": [
    "# Test Vidio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab5df4",
   "metadata": {},
   "source": [
    "## Realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207767d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T01:14:09.436364Z",
     "start_time": "2023-08-07T01:12:33.378112Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import pickle\n",
    "\n",
    "def read_model(filename, path=\"\"):\n",
    "    with open(os.path.join(path, filename), 'rb') as in_name:\n",
    "        model = pickle.load(in_name)\n",
    "        return model\n",
    "    \n",
    "\n",
    "color = (255, 0, 0)\n",
    "cap = cv2.VideoCapture(0) # 0 jika kamera\n",
    "model = read_model(\"../weight/model_haar_sift_knn.pkl\", path=\"\") #load model\n",
    "label_dict = np.load('../weight/label_knn.npy', allow_pickle=True).item() #load label\n",
    "\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret , frame = cap.read() #baca vidio dengan looping gambar\n",
    "    if ret:\n",
    "        face_roi = []# Load Haar Cascade classifier for face detection\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        # Convert the image to grayscale (required for face detection)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the image using the face_cascade\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "        # Draw bounding boxes around the detected faces and display the image\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Draw a rectangle around the detected face\n",
    "            face_roi = frame[y:y+h, x:x+w]\n",
    "            cv2.rectangle(frame, (x-5, y-5), (x + w+5, y + h+5), (0, 255, 0), 4)#beri rectangle dan beri overlap sebesar 5\n",
    "            muka = cv2.resize(face_roi, (225,225), interpolation = cv2.INTER_AREA)#wajib sama dengan citra inputan trainer\n",
    "            #sift\n",
    "            sift = cv2.SIFT_create(nfeatures=500, nOctaveLayers=9, contrastThreshold=0.03, edgeThreshold=10, sigma=1.6)\n",
    "            kpts, des = sift.detectAndCompute(muka, None)\n",
    "            print(f\" jumlah keypoint terbentuk {len(kpts)}\")\n",
    "            if(len(kpts) >= 200): #karna sistem akan akan menggunakan shape 200 minimal\n",
    "                cv2.imshow(\"Haar\",muka)\n",
    "                # Marking the keypoint on the image using circles\n",
    "                img=cv2.drawKeypoints(muka, kpts , muka ,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "                # bovw\n",
    "                #kmeans works only on float, so convert integers to float\n",
    "                descriptors_float = des.astype(float)  \n",
    "                # Perform k-means clustering and vector quantization\n",
    "                from scipy.cluster.vq import kmeans, vq\n",
    "                k = 200  #dari total 500 diambil hanya 200\n",
    "                voc, variance = kmeans(obs=descriptors_float, k_or_guess=k, iter=5) \n",
    "                # Calculate the histogram of features and represent them as vector\n",
    "                #vq Assigns codes from a code book to observations.\n",
    "                im_features = np.zeros((1, k), \"float32\")\n",
    "                for i in range(1):\n",
    "                    words, distance = vq(des,voc)\n",
    "                    for w in words:\n",
    "                        im_features[i][w] += 1\n",
    "                \n",
    "                cv2.imshow(\"Sift\",img)\n",
    "                prediksi= model.predict(im_features) #prediksi\n",
    "                key_found = [key for key, value in label_dict.items() if value == prediksi] #dapatkan namanya\n",
    "                cv2.putText(frame, f\"Deteksi : {key_found[0]}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),2)\n",
    "        cv2.imshow(\"Video Original\" , frame)\n",
    "    else:\n",
    "        print('no video')\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        continue\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf9947",
   "metadata": {},
   "source": [
    "## Input Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0263706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import pickle\n",
    "\n",
    "def read_model(filename, path=\"\"):\n",
    "    with open(os.path.join(path, filename), 'rb') as in_name:\n",
    "        model = pickle.load(in_name)\n",
    "        return model\n",
    "    \n",
    "\n",
    "color = (255, 0, 0)\n",
    "video_path = input(\"Masukkan path video: \")  # Meminta pengguna untuk memasukkan path video\n",
    "cap = cv2.VideoCapture(video_path)  # Membaca video dari file yang ditentukan\n",
    "\n",
    "model = read_model(\"../weight/model_haar_sift_knn.pkl\", path=\"\") #load model\n",
    "label_dict = np.load('../weight/label_knn.npy', allow_pickle=True).item() #load label\n",
    "\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret , frame = cap.read() #baca video dengan looping gambar\n",
    "    if ret:\n",
    "        face_roi = []# Load Haar Cascade classifier for face detection\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        # Convert the image to grayscale (required for face detection)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the image using the face_cascade\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "        # Draw bounding boxes around the detected faces and display the image\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Draw a rectangle around the detected face\n",
    "            face_roi = frame[y:y+h, x:x+w]\n",
    "            cv2.rectangle(frame, (x-5, y-5), (x + w+5, y + h+5), (0, 255, 0), 4)#beri rectangle dan beri overlap sebesar 5\n",
    "            muka = cv2.resize(face_roi, (225,225), interpolation = cv2.INTER_AREA)#wajib sama dengan citra inputan trainer\n",
    "            #sift\n",
    "            sift = cv2.SIFT_create(nfeatures=500, nOctaveLayers=9, contrastThreshold=0.03, edgeThreshold=10, sigma=1.6)\n",
    "            kpts, des = sift.detectAndCompute(muka, None)\n",
    "            print(f\" jumlah keypoint terbentuk {len(kpts)}\")\n",
    "            if(len(kpts) >= 200): #karna sistem akan akan menggunakan shape 200 minimal\n",
    "                cv2.imshow(\"Haar\",muka)\n",
    "                # Marking the keypoint on the image using circles\n",
    "                img=cv2.drawKeypoints(muka, kpts , muka ,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "                # bovw\n",
    "                #kmeans works only on float, so convert integers to float\n",
    "                descriptors_float = des.astype(float)  \n",
    "                # Perform k-means clustering and vector quantization\n",
    "                from scipy.cluster.vq import kmeans, vq\n",
    "                k = 200  #dari total 500 diambil hanya 200\n",
    "                voc, variance = kmeans(obs=descriptors_float, k_or_guess=k, iter=5) \n",
    "                # Calculate the histogram of features and represent them as vector\n",
    "                #vq Assigns codes from a code book to observations.\n",
    "                im_features = np.zeros((1, k), \"float32\")\n",
    "                for i in range(1):\n",
    "                    words, distance = vq(des,voc)\n",
    "                    for w in words:\n",
    "                        im_features[i][w] += 1\n",
    "                \n",
    "                cv2.imshow(\"Sift\",img)\n",
    "                prediksi= model.predict(im_features) #prediksi\n",
    "                key_found = [key for key, value in label_dict.items() if value == prediksi] #dapatkan namanya\n",
    "                cv2.putText(frame, f\"Deteksi : {key_found[0]}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),2)\n",
    "        cv2.imshow(\"Video Original\" , frame)\n",
    "    else:\n",
    "        print('no video')\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        continue\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
