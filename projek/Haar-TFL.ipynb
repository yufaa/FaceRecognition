{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-29T04:19:37.327Z"
    }
   },
   "source": [
    "\n",
    "latihan yang dipelajari meliputi:    \n",
    "\n",
    "1. preprocessing\n",
    "2. load gambar dalam sebuah folder \n",
    "3. spliting dataset train test\n",
    "4. klasifikasi model evaluasi\n",
    "5. Find best parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T03:21:33.705601Z",
     "start_time": "2023-08-10T03:21:29.166615Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load the input image\n",
    "img_path = '../dataset/Yudha/IMG_4828.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Convert the image to grayscale (required for face detection)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the image using the face_cascade\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "\n",
    "# Show the original image with the detected face\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image with Detected Face')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Draw bounding boxes around the detected faces and display the image\n",
    "for (x, y, w, h) in faces:\n",
    "    # Draw a rectangle around the detected face\n",
    "    cv2.rectangle(img, (x-5, y-5), (x + w+5, y + h+5), (0, 255, 0), 4)#beri rectangle dan beri overlap sebesar 5\n",
    "    face_roi = img[y:y+h, x:x+w]\n",
    "\n",
    "    # Show the original image with the detected faces and bounding boxes\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original Image with Detected Faces')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Roi')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T03:21:34.278100Z",
     "start_time": "2023-08-10T03:21:33.736252Z"
    }
   },
   "outputs": [],
   "source": [
    "#image preprocessing\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "# img=cv2.imread('../dataset/Kirei/IMG_5058.jpg') #baca file gambar dari direktori dengan menggunakan open cv\n",
    "img = face_roi\n",
    "#plt digunakan untuk menampilkan plot / gambar\n",
    "plt.figure()\n",
    "plt.title(\"Inputan\")\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) #menampilkan gambar\n",
    "plt.show() #menampilkan plot\n",
    "\n",
    "convert = img/255.0\n",
    "plt.figure()\n",
    "plt.title(\"prepro standarisasi\") #membuat judul pada plot\n",
    "plt.imshow(convert) #menampilkan gambar\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T12:01:08.545331Z",
     "start_time": "2023-08-03T12:01:08.535675Z"
    }
   },
   "source": [
    "train sendiri objek baru\n",
    "https://amin-ahmadi.com/cascade-trainer-gui/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T02:36:26.614747Z",
     "start_time": "2023-03-10T02:36:26.603741Z"
    }
   },
   "source": [
    "plt digunakan untuk membuat plot gambar <br>\n",
    "cv2 perintah open cv untuk gambar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## membaca data dan memberi label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T04:04:13.607711Z",
     "start_time": "2023-08-10T04:04:13.597451Z"
    }
   },
   "outputs": [],
   "source": [
    "def haar(img):\n",
    "    status = False\n",
    "    face_roi = []\n",
    "    # Load Haar Cascade classifier for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    # Convert the image to grayscale (required for face detection)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the image using the face_cascade\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "    # Draw bounding boxes around the detected faces and display the image\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw a rectangle around the detected face\n",
    "        face_roi = img[y:y+h, x:x+w]\n",
    "        status = True\n",
    "    return status,face_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T03:44:43.006620Z",
     "start_time": "2023-08-10T03:41:51.717987Z"
    }
   },
   "outputs": [],
   "source": [
    "#menentukan direktori/folder data citra yang akan dibuka\n",
    "dirname = '../dataset/'  \n",
    "\n",
    "#menentukan ukuran tinggi dan lebar gambar\n",
    "height = 224\n",
    "width = 224\n",
    "dim = (width, height)\n",
    "\n",
    "#mengumpulkan data citra yang akan dibuka dalam satu array\n",
    "tampungan_data= [] \n",
    "tampungan_label=[]\n",
    "for path, subdirs, files in os.walk(dirname):\n",
    "    print(path)\n",
    "    for name in files:\n",
    "        img_path = (os.path.join(path, name))  #baca path data\n",
    "        if (img_path.endswith(\"jpg\")): #dengan file berekstensi jpg\n",
    "            img = cv2.imread(img_path) #baca gambar\n",
    "            \n",
    "            path_parts = path.split('/')\n",
    "            # Mengambil elemen terakhir dari path_parts sebagai kata terakhir\n",
    "            last_word = path_parts[-1]\n",
    "            #preprocessing data / segmentasi  boleh dilakukan disini\n",
    "            status, gambar_haar = haar(img)\n",
    "            if(status):\n",
    "                resized=cv2.resize(gambar_haar,dim, interpolation=cv2.INTER_LINEAR) #resize\n",
    "                tampungan_data.append(resized/255.0) #menumpuk gambar blur pada array tampungan dan di sampling\n",
    "                tampungan_label.append(last_word)\n",
    "    X = np.array(tampungan_data) \n",
    "    y = np.array(tampungan_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T03:44:43.661187Z",
     "start_time": "2023-08-10T03:44:43.490653Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "list_label=np.unique(y) #mendapatkan label unik\n",
    "label_dict = {label: idx for idx, label in enumerate(list_label)} #masukkan dalam list\n",
    "print(label_dict)\n",
    "label_numerik = [label_dict[s] for s in y] #ubah kedalam numerik\n",
    "label_numerik_array = np.array(label_numerik)\n",
    "\n",
    "# Visualisasikan dalam jumlah dalam plot\n",
    "sns.countplot(x=label_numerik_array)\n",
    "plt.xlabel('Numeric Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count Plot for Numeric Labels')\n",
    "plt.show()  \n",
    "\n",
    "# simpan dalam file npy untuk labeling\n",
    "np.save('../weight/label_knn.npy', label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tampilkan data hasil preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T03:44:52.451155Z",
     "start_time": "2023-08-10T03:44:51.502057Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Randomly select 6 indices from the data\n",
    "random_indices = np.random.choice(len(X), 6, replace=False)\n",
    "\n",
    "# Plot the images\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, idx in enumerate(random_indices):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(X[idx])\n",
    "    plt.title(\"Label: \" + str(y[idx]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T02:49:29.113975Z",
     "start_time": "2023-03-13T02:49:29.099972Z"
    }
   },
   "source": [
    "<img src=\"https://www.researchgate.net/profile/Brian-Mwandau/publication/325870973/figure/fig6/AS:639531594285060@1529487622235/Train-Test-Data-Split_W640.jpg\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T03:44:57.328326Z",
     "start_time": "2023-08-10T03:44:57.020351Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #library untuk train test split\n",
    "\n",
    "#melakukan splitting data\n",
    "\n",
    "\n",
    "# First, split data into train and temp sets (70% train, 30% temp)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, label_numerik_array, test_size=0.3, random_state=42, stratify=label_numerik_array)\n",
    "\n",
    "# Next, split the temp set into validation and test sets (50% validation, 50% test)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Print the sizes of each set\n",
    "print(\"Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikasi Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>FLOW KLASIFIKASI</b><br>\n",
    "<img src=\"TT.png\">\n",
    "<b>MobileNetV2</b><br>\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1280/format:webp/0*Htkmfq0G4glxNgFF.png\">\n",
    "<hr>\n",
    "<b>Metode evaluasi</b><br>\n",
    "<img src=\"https://dataq.files.wordpress.com/2013/06/rumus.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T03:46:21.214281Z",
     "start_time": "2023-08-10T03:46:18.776329Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import keras \n",
    "from tensorflow.keras.applications import MobileNetV2 as Mdl\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "def mobilenet(img_height,img_width, channel):\n",
    "    base_model = Mdl(weights=\"imagenet\", include_top=False, input_shape=(img_height,img_width, channel)) #model TF IMAGENET\n",
    "\n",
    "    for layer in base_model.layers: #FREEZ ALL LAYER karena tfl\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model= tf.keras.Sequential()\n",
    "    model.add(base_model) #tambahkan beberapa layer\n",
    "    x = model.output\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    predictions = tf.keras.layers.Dense(3, activation=\"softmax\")(x) #softmax untuk multiclass\n",
    "    model = Model(inputs=model.input, outputs=predictions)\n",
    "    return model\n",
    "model=mobilenet(224,224, 3).summary() #tampilkan bentuk arsitekturnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T03:48:50.279524Z",
     "start_time": "2023-08-10T03:46:29.881622Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session() #hapus cache keras  \n",
    "\n",
    "model = mobilenet(224,224,3) #panggil model\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001),loss='sparse_categorical_crossentropy', metrics = ['accuracy']) #compile model\n",
    "callbacks = [ModelCheckpoint(f\"../weight/best_weight.h5\", monitor='val_loss', save_best_only=True)] #simpan model\n",
    "history = model.fit(X_train,y_train,validation_data=(X_val,y_val), batch_size=32, epochs=30,\n",
    "                          verbose=0, callbacks=callbacks, workers=-1) #train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisasi Loos dan Akurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T03:49:43.468212Z",
     "start_time": "2023-08-10T03:49:42.981493Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot grafik kiri\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "# Plot grafik kanan\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])\n",
    "plt.tight_layout()\n",
    "# Simpan gambar ke file\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T03:52:12.280829Z",
     "start_time": "2023-08-10T03:52:11.193458Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, batch_size=1) #test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confussion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T03:52:26.029388Z",
     "start_time": "2023-08-10T03:52:25.837065Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "multiclass_predictions = np.argmax(y_pred, axis=1) #proses probabilitas\n",
    "cm = confusion_matrix(multiclass_predictions, y_test)#plot cm\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_dict, yticklabels=label_dict)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T03:53:18.955249Z",
     "start_time": "2023-08-10T03:53:18.940467Z"
    }
   },
   "outputs": [],
   "source": [
    "report = classification_report(multiclass_predictions, y_test)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "support: jumlah sampel di setiap kelas. \n",
    "Ini memberikan gambaran tentang seberapa seimbang dataset kita dan apakah terdapat kelas yang mungkin kurang terwakili dalam dataset.\n",
    "\n",
    "macro avg: nilai rata-rata dari metrik evaluasi untuk setiap kelas. \n",
    "Rata-rata ini diperoleh dengan menghitung rata-rata aritmatika dari skor presisi, recall, dan f1-score dari setiap kelas, tanpa mempertimbangkan frekuensi setiap kelas. \n",
    "Metrik ini berguna untuk mengevaluasi performa model secara keseluruhan, terlepas dari seberapa seimbang atau tidak seimbang kelas-kelas pada dataset.\n",
    "\n",
    "micro avg: nilai rata-rata dari metrik evaluasi di seluruh kelas, dengan mempertimbangkan jumlah contoh yang benar diklasifikasikan secara agregat. \n",
    "Dalam hal ini, mikro rata-rata memperlakukan setiap contoh sebagai satu unit, dan mempertimbangkan jumlah contoh yang benar diklasifikasikan sebagai satu keseluruhan. Metrik ini berguna untuk mengevaluasi performa model pada dataset yang tidak seimbang.\n",
    "\n",
    "accuracy: rasio antara jumlah contoh yang diklasifikasikan dengan benar dan jumlah contoh keseluruhan.\n",
    "\n",
    "precision: rasio antara jumlah contoh positif yang diklasifikasikan dengan benar dan jumlah contoh yang diklasifikasikan sebagai positif oleh model.\n",
    "\n",
    "recall: rasio antara jumlah contoh positif yang diklasifikasikan dengan benar dan jumlah contoh yang sebenarnya positif dalam dataset.\n",
    "\n",
    "f1-score: rata-rata harmonik dari presisi dan recall. Metrik ini menggabungkan kedua nilai untuk memberikan skor yang mencerminkan keseimbangan antara presisi dan recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uji testing data baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T03:57:27.000151Z",
     "start_time": "2023-08-10T03:57:24.320145Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "url= '../dataset/Yudha/IMG_4940.jpg'\n",
    "img=cv2.imread(url)\n",
    "plt.figure()\n",
    "plt.title(\"Data Test\")\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "#pastikan langkah preprocessing yang dilakukan sama dengan data train\n",
    "status,haarnya=haar(img)\n",
    "convert = haarnya/255.0\n",
    "img_resize = cv2.resize(convert,(224,224))\n",
    "#tampilkan hasil\n",
    "plt.figure()\n",
    "plt.title(\"Hasil preprocessing\")\n",
    "plt.imshow(img_resize)\n",
    "plt.show()\n",
    "\n",
    "test = img_resize.reshape((1, 224, 224, 3))\n",
    "\n",
    "print(f\"ukuran gambar test {test.shape}\") #sama dengan input shape\n",
    "\n",
    "# Mengecek hasil klasifikasi pada salah satu dataset\n",
    "probability=model.predict(test)\n",
    "print(f\"nilai probabilitas {probability}\") #tampilkan nilai probabilitas tiap kelas\n",
    "\n",
    "\n",
    "\n",
    "for ind,val in enumerate(label_dict): #mendapatkan nama kelas dan hasil akurasi\n",
    "    print(f'{val} = {probability[0][ind]*100}%')\n",
    "    \n",
    "    \n",
    "hasil = np.argmax(probability, axis=-1) #mendapatkan kelas dari probabilitas terbaik\n",
    "key_found = [key for key, value in label_dict.items() if value == hasil] #dapatkan namanya\n",
    "print(f\"prediksinya: {key_found}\")\n",
    "print(f\"The predicted image is : {str(hasil)} -> {key_found}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T04:04:25.817473Z",
     "start_time": "2023-08-10T04:04:17.957816Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Load the model\n",
    "model_path ='../weight/best_weight.h5'\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Vidio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T04:06:16.684942Z",
     "start_time": "2023-08-10T04:05:45.136130Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import pickle\n",
    "\n",
    "\n",
    "color = (255, 0, 0)\n",
    "cap = cv2.VideoCapture(0) # 0 jika kamera\n",
    "label_dict = np.load('../weight/label_knn.npy', allow_pickle=True).item() #load label\n",
    "\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret , frame = cap.read() #baca vidio dengan looping gambar\n",
    "    if ret:\n",
    "        face_roi = []# Load Haar Cascade classifier for face detection\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        # Convert the image to grayscale (required for face detection)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the image using the face_cascade\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "        # Draw bounding boxes around the detected faces and display the image\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Draw a rectangle around the detected face\n",
    "            face_roi = frame[y:y+h, x:x+w]\n",
    "            cv2.rectangle(frame, (x-5, y-5), (x + w+5, y + h+5), (0, 255, 0), 4)#beri rectangle dan beri overlap sebesar 5\n",
    "\n",
    "            convert = face_roi/255.0 #preprocessing\n",
    "            muka = cv2.resize(convert, (224,224), interpolation = cv2.INTER_AREA)#wajib sama dengan citra inputan trainer\n",
    "            cv2.imshow(\"Detect\",muka)\n",
    "            \n",
    "            gambar_resize=muka.reshape((1, 224, 224, 3))\n",
    "            probability= model.predict(gambar_resize) #prediksi\n",
    "            hasil = np.argmax(probability, axis=-1) #mendapatkan kelas dari probabilitas terbaik\n",
    "            key_found = [key for key, value in label_dict.items() if value == hasil] #dapatkan namanya\n",
    "            cv2.putText(frame, f\"Deteksi : {key_found[0]}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),2)\n",
    "            cv2.imshow(\"Detect\",muka)\n",
    "        cv2.imshow(\"Video Original\" , frame)\n",
    "    else:\n",
    "        print('no video')\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        continue\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "color = (255, 0, 0)\n",
    "video_path = input(\"Masukkan path video: \")  # Memasukkan path video secara manual\n",
    "cap = cv2.VideoCapture(video_path)  # Membaca video dari file\n",
    "\n",
    "label_dict = np.load('../weight/label_knn.npy', allow_pickle=True).item()  # Load label\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()  # Baca frame video\n",
    "    if ret:\n",
    "        face_roi = []  # Load Haar Cascade classifier for face detection\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        # Convert the image to grayscale (required for face detection)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the image using the face_cascade\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "        # Draw bounding boxes around the detected faces and display the image\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Draw a rectangle around the detected face\n",
    "            face_roi = frame[y:y+h, x:x+w]\n",
    "            cv2.rectangle(frame, (x-5, y-5), (x + w+5, y + h+5), (0, 255, 0), 4)  # Beri rectangle dan beri overlap sebesar 5\n",
    "\n",
    "            convert = face_roi/255.0  # Preprocessing\n",
    "            muka = cv2.resize(convert, (224, 224), interpolation=cv2.INTER_AREA)  # Wajib sama dengan citra inputan trainer\n",
    "            cv2.imshow(\"Detect\", muka)\n",
    "\n",
    "            gambar_resize = muka.reshape((1, 224, 224, 3))\n",
    "            probability = model.predict(gambar_resize)  # Prediksi\n",
    "            hasil = np.argmax(probability, axis=-1)  # Mendapatkan kelas dari probabilitas terbaik\n",
    "            key_found = [key for key, value in label_dict.items() if value == hasil]  # Dapatkan namanya\n",
    "            cv2.putText(frame, f\"Deteksi : {key_found[0]}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.imshow(\"Detect\", muka)\n",
    "        cv2.imshow(\"Video Original\", frame)\n",
    "    else:\n",
    "        print('Tidak ada video')\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        continue\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
