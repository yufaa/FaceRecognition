{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a021baa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T03:59:53.061099Z",
     "start_time": "2023-08-04T03:59:52.419976Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "def haar(img):\n",
    "    face_roi = []\n",
    "    status = False\n",
    "    # Load Haar Cascade classifier for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    # Convert the image to grayscale (required for face detection)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the image using the face_cascade\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "    # Draw bounding boxes around the detected faces and display the image\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw a rectangle around the detected face\n",
    "        face_roi = img[y:y+h, x:x+w]\n",
    "        status = True\n",
    "    return status,face_roi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7df1c79",
   "metadata": {},
   "source": [
    "# SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd656db",
   "metadata": {},
   "source": [
    "<img src=\"https://www.codeproject.com/KB/recipes/619039/SIFT.JPG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71680c06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T03:59:54.855905Z",
     "start_time": "2023-08-04T03:59:53.380390Z"
    }
   },
   "outputs": [],
   "source": [
    "# Important NOTE: Use opencv <= 3.4.2.16 as\n",
    "# SIFT is no longer available in\n",
    "# opencv > 3.4.2.16\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading the image\n",
    "img = cv2.imread('../dataset/Yudha/IMG_4828.jpg')\n",
    "status,haarnya=haar(img)\n",
    "# Applying SIFT detector\n",
    "sift = cv2.SIFT_create(500)\n",
    "kpts, des = sift.detectAndCompute(haarnya, None)\n",
    "# Marking the keypoint on the image using circles\n",
    "img=cv2.drawKeypoints(haarnya, kpts , haarnya ,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "print(f\" jumlah keypoint terbentuk {len(kpts)}\")\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd91e2",
   "metadata": {},
   "source": [
    "# bovw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dc8a8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T03:59:57.515291Z",
     "start_time": "2023-08-04T03:59:57.095877Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#kmeans works only on float, so convert integers to float\n",
    "descriptors_float = des.astype(float)  \n",
    "\n",
    "# Perform k-means clustering and vector quantization\n",
    "\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "k = 200  #dari total 500 diambil hanya 200\n",
    "voc, variance = kmeans(obs=descriptors_float, k_or_guess=k, iter=5) \n",
    "\n",
    "\n",
    "# Calculate the histogram of features and represent them as vector\n",
    "#vq Assigns codes from a code book to observations.\n",
    "im_features = np.zeros((1, k), \"float32\")\n",
    "for i in range(1):\n",
    "    words, distance = vq(des,voc)\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "print(im_features.shape)\n",
    "print(im_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b4283",
   "metadata": {},
   "source": [
    "# HAAR+ SIFT+ BOVW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc4748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T01:31:10.439662Z",
     "start_time": "2023-08-07T01:31:10.429566Z"
    }
   },
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JhFCP1CjF7fRYt9pLldMsw.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0994a27",
   "metadata": {},
   "source": [
    "selengkapnya tentang haar : https://ai.plainenglish.io/terminologies-used-in-face-detection-with-haar-cascade-classifier-open-cv-6346c5c926c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a24a5",
   "metadata": {},
   "source": [
    "<img src=\"https://www.codeproject.com/KB/recipes/619039/bag-of-features1May09.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a47927",
   "metadata": {},
   "source": [
    "selengkapnya tentang sift haar : https://www.codeproject.com/Articles/619039/Bag-of-Features-Descriptor-on-SIFT-Features-with-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ca128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:02:37.486305Z",
     "start_time": "2023-08-04T04:00:00.028872Z"
    }
   },
   "outputs": [],
   "source": [
    "#menentukan direktori/folder data citra yang akan dibuka\n",
    "dirname = '../dataset/'  \n",
    "\n",
    "#menentukan ukuran tinggi dan lebar gambar\n",
    "height = 225\n",
    "width = 225\n",
    "dim = (width, height)\n",
    "#BRISK is a good replacement to SIFT. ORB also works but didn;t work well for this example\n",
    "# brisk = cv2.BRISK_create(30)\n",
    "sift = cv2.SIFT_create()\n",
    "#mengumpulkan data citra yang akan dibuka dalam satu array\n",
    "tampungan_data = [] \n",
    "tampungan_label = []\n",
    "for path, subdirs, files in os.walk(dirname):\n",
    "    print(path)\n",
    "    for name in files:\n",
    "        img_path = (os.path.join(path, name))  #baca path data\n",
    "        if (img_path.endswith(\"jpg\")): #dengan file berekstensi jpg\n",
    "            img = cv2.imread(img_path) #baca gambar\n",
    "            status, haarnya = haar(img)\n",
    "            if(status):\n",
    "                resized=cv2.resize(haarnya,dim, interpolation=cv2.INTER_LINEAR) #resize\n",
    "                kpts, des = sift.detectAndCompute(resized, None)\n",
    "                tampungan_data.append(des)\n",
    "                \n",
    "                path_parts = path.split('/')\n",
    "                # Mengambil elemen terakhir dari path_parts sebagai kata terakhir\n",
    "                last_word = path_parts[-1]\n",
    "                #preprocessing data / segentasi  boleh dilakukan disini\n",
    "                tampungan_label.append(last_word)\n",
    "    X = np.array(tampungan_data, dtype=object) \n",
    "    y = np.array(tampungan_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72825f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:04:05.720153Z",
     "start_time": "2023-08-04T04:03:58.154939Z"
    }
   },
   "outputs": [],
   "source": [
    "descriptors = None\n",
    "for descriptor in X:\n",
    "    if descriptors is None:\n",
    "        descriptors = descriptor\n",
    "    else:\n",
    "        descriptors = np.vstack((descriptors, descriptor))\n",
    "\n",
    "#kmeans works only on float, so convert integers to float\n",
    "descriptors_float = descriptors.astype(float)  \n",
    "# Perform k-means clustering and vector quantization\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "\n",
    "k = 200  #k means with 100 clusters gives lower accuracy for the aeroplane example\n",
    "voc, variance = kmeans(obs=descriptors_float, k_or_guess=k, iter=5) \n",
    "\n",
    "# Calculate the histogram of features and represent them as vector\n",
    "#vq Assigns codes from a code book to observations.\n",
    "im_features = np.zeros((len(y), k), \"float32\")\n",
    "for i in range(len(y)):\n",
    "    words, distance = vq(X[i],voc)\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "print(im_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c10cc71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:04:09.683785Z",
     "start_time": "2023-08-04T04:04:08.295882Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "list_label=np.unique(y) #mendapatkan label unik\n",
    "label_dict = {label: idx for idx, label in enumerate(list_label)} #masukkan dalam list\n",
    "print(f\"{label_dict} jumlah data: {len(y)}\")\n",
    "\n",
    "label_numerik = [label_dict[s] for s in y] #ubah kedalam numerik\n",
    "label_numerik_array = np.array(label_numerik)\n",
    "\n",
    "# Visualisasikan dalam jumlah dalam plot\n",
    "sns.countplot(x=label_numerik_array)\n",
    "plt.xlabel('Numeric Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count Plot for Numeric Labels')\n",
    "plt.show()  \n",
    "\n",
    "# simpan dalam file npy untuk labeling\n",
    "np.save('../weight/label_knn.npy', label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d5ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:04:12.065376Z",
     "start_time": "2023-08-04T04:04:11.844356Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #library untuk train test split\n",
    "\n",
    "#melakukan splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(im_features, label_numerik_array,test_size=0.20, stratify=label_numerik_array) \n",
    "#train size adalah persentase data test yang di-split dengan proporsi label yang sama\n",
    "\n",
    "print(\"X_train: \"+str(X_train.shape))\n",
    "print(\"X_test: \"+str(X_test.shape))\n",
    "print(\"y_train: \"+str(y_train.shape))\n",
    "print(\"y_test: \"+str(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc48e647",
   "metadata": {},
   "source": [
    "# Kfold Untuk Model Tebaik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697667cb",
   "metadata": {},
   "source": [
    "<img src=\"https://i.stack.imgur.com/z6lTD.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d907ad",
   "metadata": {},
   "source": [
    "selengkapnya stratifiedKFold: https://www.geeksforgeeks.org/stratified-k-fold-cross-validation/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed21b3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T01:36:10.117034Z",
     "start_time": "2023-08-07T01:36:10.110376Z"
    }
   },
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/0*ItVKiyx2F3ZU8zV5\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbe32a0",
   "metadata": {},
   "source": [
    "selengkapnya knn: http://labdas.si.fti.unand.ac.id/2022/03/20/penjelasan-cara-kerja-algoritma-k-nearest-neighbor-knn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa697c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:06:06.004376Z",
     "start_time": "2023-08-04T04:06:05.766350Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold #melakukan validasi dengan hasil skor akurasi dengan cross validation\n",
    "parameters = {'n_neighbors':[1, 3, 5, 7],\n",
    "             'metric': ['minkowski','euclidean','manhattan']} #masukan parameter yang akan dilakukan\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "# Create the StratifiedKFold cross-validation method\n",
    "stratified_kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "clf = GridSearchCV(model, parameters, verbose=3, cv=stratified_kfold, scoring='accuracy') #panggil gridsearch\n",
    "clf.fit(X_train,y_train) #train data\n",
    "best = clf.best_estimator_ #model terbaik\n",
    "print(clf.best_estimator_) #model terbaik\n",
    "print(clf.best_score_) #akurasi terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6a0db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:06:13.093327Z",
     "start_time": "2023-08-04T04:06:12.776408Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the metric distances for each label separately with different marker shapes\n",
    "plt.figure(figsize=(8, 6))\n",
    "distances, _ = best.kneighbors(X_train)\n",
    "\n",
    "# Dictionary to map label to marker shape\n",
    "marker_dict = {0: 's', 1: '^', 2: 'o'}\n",
    "\n",
    "for label in np.unique(y_train):\n",
    "    # Get the indices of data points belonging to the current label\n",
    "    label_indices = np.where(y_train == label)[0]\n",
    "    \n",
    "    # Get the distances to the k nearest neighbors for data points of the current label\n",
    "    label_distances = np.mean(distances[label_indices], axis=1)\n",
    "    \n",
    "    # Plot the distances for the current label with the corresponding marker shape\n",
    "    plt.scatter(X_train[label_indices, 0], X_train[label_indices, 1], c=label_distances, cmap='plasma', edgecolors='k', label=f\"Class {label}\", marker=marker_dict[label])\n",
    "\n",
    "plt.colorbar(label='Average Distance to k Nearest Neighbors')\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.title(\"KNN - Metric Distance Visualization for Each Label\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aceeb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:06:31.669362Z",
     "start_time": "2023-08-04T04:06:31.655875Z"
    }
   },
   "outputs": [],
   "source": [
    "best.fit(X_train,y_train)\n",
    "y_pred = best.predict(X_test) #predict untuk memprediksi data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57eb2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:07:27.181148Z",
     "start_time": "2023-08-04T04:07:27.004219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Plot the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a620a12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:07:27.889821Z",
     "start_time": "2023-08-04T04:07:27.874797Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred)) #evaluasi hasil best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea6ae6",
   "metadata": {},
   "source": [
    "# Test Data Baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f142fd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:07:40.936234Z",
     "start_time": "2023-08-04T04:07:39.020562Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "url= '../dataset/Yudha/IMG_4941.jpg'\n",
    "img=cv2.imread(url)\n",
    "plt.figure()\n",
    "plt.title(\"Data Test\")\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "#pastikan langkah preprocessing yang dilakukan sama dengan data train\n",
    "status,haarnya=haar(img)\n",
    "img_resize = cv2.resize(haarnya,(225,225))\n",
    "#tampilkan hasil\n",
    "plt.figure()\n",
    "plt.title(\"Hasil preprocessing\")\n",
    "plt.imshow(cv2.cvtColor(img_resize, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Hasil Sift\")\n",
    "# sift = cv2.SIFT_create()\n",
    "sift = cv2.SIFT_create(nfeatures=500, nOctaveLayers=9, contrastThreshold=0.03, edgeThreshold=10, sigma=1.6)\n",
    "kpts, des = sift.detectAndCompute(img_resize, None)\n",
    "# Marking the keypoint on the image using circles\n",
    "img=cv2.drawKeypoints(img_resize, kpts , img_resize ,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "print(f\" jumlah keypoint terbentuk {len(kpts)}\")\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# bovw\n",
    "\n",
    "#kmeans works only on float, so convert integers to float\n",
    "descriptors_float = des.astype(float)  \n",
    "# Perform k-means clustering and vector quantization\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "k = 200  #dari total 500 diambil hanya 200\n",
    "voc, variance = kmeans(obs=descriptors_float, k_or_guess=k, iter=5) \n",
    "# Calculate the histogram of features and represent them as vector\n",
    "#vq Assigns codes from a code book to observations.\n",
    "im_features = np.zeros((1, k), \"float32\")\n",
    "for i in range(1):\n",
    "    words, distance = vq(des,voc)\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "print(im_features.shape)\n",
    "\n",
    "print(f\"ukuran data test {im_features.shape}\") #sama dengan input shape\n",
    "\n",
    "# Mengecek hasil klasifikasi pada salah satu dataset\n",
    "probability=best.predict_proba(im_features)\n",
    "print(f\"nilai probabilitas {probability}\") #tampilkan nilai probabilitas tiap kelas\n",
    "\n",
    "\n",
    "\n",
    "for ind,val in enumerate(label_dict): #mendapatkan nama kelas dan hasil akurasi\n",
    "    print(f'{val} = {probability[0][ind]*100}%')\n",
    "    \n",
    "    \n",
    "hasil = np.argmax(probability, axis=-1) #mendapatkan kelas dari probabilitas terbaik\n",
    "key_found = [key for key, value in label_dict.items() if value == hasil] #dapatkan namanya\n",
    "print(f\"prediksinya: {key_found}\")\n",
    "print(f\"The predicted image is : {str(hasil)} -> {key_found}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9083a7d0",
   "metadata": {},
   "source": [
    "# Simpan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f980e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(best, open('../weight/model_haar_sift_knn_optimasi.pkl', 'wb')) #simpan dalam file.pkl\n",
    "# loaded_model = pickle.load(open('model_haar_knn.pkl', 'rb')) # load model yg dibuat\n",
    "\n",
    "# result = loaded_model.predict(X_test) \n",
    "# print(classification_report(y_test, result)) #evaluasi hasil best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import pickle\n",
    "\n",
    "def read_model(filename, path=\"\"):\n",
    "    with open(os.path.join(path, filename), 'rb') as in_name:\n",
    "        model = pickle.load(in_name)\n",
    "        return model\n",
    "    \n",
    "\n",
    "color = (255, 0, 0)\n",
    "cap = cv2.VideoCapture(0) # 0 jika kamera\n",
    "model = read_model(\"../weight/model_haar_sift_knn.pkl\", path=\"\") #load model\n",
    "label_dict = np.load('../weight/label_knn.npy', allow_pickle=True).item() #load label\n",
    "\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret , frame = cap.read() #baca vidio dengan looping gambar\n",
    "    if ret:\n",
    "        face_roi = []# Load Haar Cascade classifier for face detection\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        # Convert the image to grayscale (required for face detection)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the image using the face_cascade\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "        # Draw bounding boxes around the detected faces and display the image\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Draw a rectangle around the detected face\n",
    "            face_roi = frame[y:y+h, x:x+w]\n",
    "            cv2.rectangle(frame, (x-5, y-5), (x + w+5, y + h+5), (0, 255, 0), 4)#beri rectangle dan beri overlap sebesar 5\n",
    "            muka = cv2.resize(face_roi, (225,225), interpolation = cv2.INTER_AREA)#wajib sama dengan citra inputan trainer\n",
    "            #sift\n",
    "            sift = cv2.SIFT_create(nfeatures=500, nOctaveLayers=9, contrastThreshold=0.03, edgeThreshold=10, sigma=1.6)\n",
    "            kpts, des = sift.detectAndCompute(muka, None)\n",
    "            print(f\" jumlah keypoint terbentuk {len(kpts)}\")\n",
    "            if(len(kpts) >= 200): #karna sistem akan akan menggunakan shape 200 minimal\n",
    "                cv2.imshow(\"Haar\",muka)\n",
    "                # Marking the keypoint on the image using circles\n",
    "                img=cv2.drawKeypoints(muka, kpts , muka ,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "                # bovw\n",
    "                #kmeans works only on float, so convert integers to float\n",
    "                descriptors_float = des.astype(float)  \n",
    "                # Perform k-means clustering and vector quantization\n",
    "                from scipy.cluster.vq import kmeans, vq\n",
    "                k = 200  #dari total 500 diambil hanya 200\n",
    "                voc, variance = kmeans(obs=descriptors_float, k_or_guess=k, iter=5) \n",
    "                # Calculate the histogram of features and represent them as vector\n",
    "                #vq Assigns codes from a code book to observations.\n",
    "                im_features = np.zeros((1, k), \"float32\")\n",
    "                for i in range(1):\n",
    "                    words, distance = vq(des,voc)\n",
    "                    for w in words:\n",
    "                        im_features[i][w] += 1\n",
    "                \n",
    "                cv2.imshow(\"Sift\",img)\n",
    "                prediksi= model.predict(im_features) #prediksi\n",
    "                key_found = [key for key, value in label_dict.items() if value == prediksi] #dapatkan namanya\n",
    "                cv2.putText(frame, f\"Deteksi : {key_found[0]}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),2)\n",
    "        cv2.imshow(\"Video Original\" , frame)\n",
    "    else:\n",
    "        print('no video')\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        continue\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895be693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import pickle\n",
    "\n",
    "def read_model(filename, path=\"\"):\n",
    "    with open(os.path.join(path, filename), 'rb') as in_name:\n",
    "        model = pickle.load(in_name)\n",
    "        return model\n",
    "    \n",
    "\n",
    "color = (255, 0, 0)\n",
    "video_path = input(\"Masukkan path video: \")  # Meminta pengguna untuk memasukkan path video\n",
    "cap = cv2.VideoCapture(video_path)  # Membaca video dari file yang ditentukan\n",
    "\n",
    "model = read_model(\"../weight/model_haar_sift_knn.pkl\", path=\"\") #load model\n",
    "label_dict = np.load('../weight/label_knn.npy', allow_pickle=True).item() #load label\n",
    "\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret , frame = cap.read() #baca video dengan looping gambar\n",
    "    if ret:\n",
    "        face_roi = []# Load Haar Cascade classifier for face detection\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        # Convert the image to grayscale (required for face detection)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the image using the face_cascade\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "        # Draw bounding boxes around the detected faces and display the image\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Draw a rectangle around the detected face\n",
    "            face_roi = frame[y:y+h, x:x+w]\n",
    "            cv2.rectangle(frame, (x-5, y-5), (x + w+5, y + h+5), (0, 255, 0), 4)#beri rectangle dan beri overlap sebesar 5\n",
    "            muka = cv2.resize(face_roi, (225,225), interpolation = cv2.INTER_AREA)#wajib sama dengan citra inputan trainer\n",
    "            #sift\n",
    "            sift = cv2.SIFT_create(nfeatures=500, nOctaveLayers=9, contrastThreshold=0.03, edgeThreshold=10, sigma=1.6)\n",
    "            kpts, des = sift.detectAndCompute(muka, None)\n",
    "            print(f\" jumlah keypoint terbentuk {len(kpts)}\")\n",
    "            if(len(kpts) >= 200): #karna sistem akan akan menggunakan shape 200 minimal\n",
    "                cv2.imshow(\"Haar\",muka)\n",
    "                # Marking the keypoint on the image using circles\n",
    "                img=cv2.drawKeypoints(muka, kpts , muka ,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "                # bovw\n",
    "                #kmeans works only on float, so convert integers to float\n",
    "                descriptors_float = des.astype(float)  \n",
    "                # Perform k-means clustering and vector quantization\n",
    "                from scipy.cluster.vq import kmeans, vq\n",
    "                k = 200  #dari total 500 diambil hanya 200\n",
    "                voc, variance = kmeans(obs=descriptors_float, k_or_guess=k, iter=5) \n",
    "                # Calculate the histogram of features and represent them as vector\n",
    "                #vq Assigns codes from a code book to observations.\n",
    "                im_features = np.zeros((1, k), \"float32\")\n",
    "                for i in range(1):\n",
    "                    words, distance = vq(des,voc)\n",
    "                    for w in words:\n",
    "                        im_features[i][w] += 1\n",
    "                \n",
    "                cv2.imshow(\"Sift\",img)\n",
    "                prediksi= model.predict(im_features) #prediksi\n",
    "                key_found = [key for key, value in label_dict.items() if value == prediksi] #dapatkan namanya\n",
    "                cv2.putText(frame, f\"Deteksi : {key_found[0]}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),2)\n",
    "        cv2.imshow(\"Video Original\" , frame)\n",
    "    else:\n",
    "        print('no video')\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        continue\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
